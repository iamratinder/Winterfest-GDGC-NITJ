# -*- coding: utf-8 -*-
"""Winterfest (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D9SYOXNOb1KpBUaCz9Lc0jk5l6g1GuiD
"""

# !pip install langchain google-generativeai feedparser oauth2client

# !pip install --upgrade langchain google-generativeai langchain-community

# !pip install langchain-google-genai

# !pip install Mastodon.py

# !pip install feedparser

# !pip install langchain groq
# !pip install --upgrade langchain langchain-community groq

import os
import feedparser
from google.colab import userdata
api_key = userdata.get('api_key')
access_token = userdata.get('access_token')

os.environ["GROQ_API_KEY"] = api_key

# !pip install requests
# !pip install newspaper3k

import feedparser
from bs4 import BeautifulSoup
import requests

import re

def fetch_google_news(topic: str):
    """Fetches top 5 news articles from Google News RSS for a given topic."""
    topic = topic.strip().replace(" ", "%20")
    rss_url = f"https://news.google.com/rss/search?q={topic}&hl=en-US&gl=US&ceid=US:en"

    feed = feedparser.parse(rss_url)
    articles = []

    for entry in feed.entries[:3]:
        match = re.search(r"url=(.*?)&", entry.link)  # Extract actual URL
        real_url = match.group(1) if match else entry.link  # If no match, use as is

        articles.append({"title": entry.title, "link": rss_url})

    return articles if articles else "No news articles found."




# ‚úÖ Function to Fetch Article Content
def fetch_article(link: str):
    """Fetches and extracts the main content from a news article URL."""
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(link, headers=headers, timeout=5)

        if response.status_code != 200:
            return f"Failed to fetch article. Status Code: {response.status_code}"

        soup = BeautifulSoup(response.text, "html.parser")

        # Extract meaningful paragraphs
        paragraphs = [p.get_text(strip=True) for p in soup.find_all("p") if len(p.get_text(strip=True)) > 50]
        article_text = " ".join(paragraphs[:10])  # Extract first 5 paragraphs

        return article_text if article_text else "No relevant content found."

    except requests.RequestException as e:
        return f"Error fetching article: {str(e)}"

fetch_article("https://www.geeksforgeeks.org/building-ai-agents-with-phidata/")

news = fetch_google_news("India's got latent")
for article in news:
    print(f"üîπ {article['title']}\nüîó {article['link']}\n")

# !pip install -qU 'langchain[groq]' langchain_community

from langchain_groq import ChatGroq

chat_model = ChatGroq(model_name="mixtral-8x7b-32768", temperature=0, api_key=os.getenv("GROQ_API_KEY"))

# ‚úÖ Function for Summarization
def summarize_news(title: str, content: str):
    """Summarizes a news article in an engaging way for social media."""
    if not content or content.startswith("Failed") or content.startswith("Error"):
        return f"Could not fetch content for '{title}'. Please check the article link manually."

    prompt = f"Summarize this news article in an engaging way for social media and make it small upto 100 characters. Also make it well formated in a great points format for the social posts make it very concise\n\nTitle: {title}\n\nContent: {content}"

    response = chat_model.invoke(prompt)
    return response.content if hasattr(response, "content") else response

def get_summarized_news(topic: str):
    """Fetches the latest news on a topic and summarizes the first available article."""
    articles = fetch_google_news(topic)
    if not articles or isinstance(articles, str):
        return "No relevant news articles found."

    first_article = articles[0]  # Select the first article
    title, link = first_article["title"], first_article["link"]

    content = fetch_article(link)

    if "Failed" in content or "Error" in content:
        return f"Could not fetch content for '{title}'. Read more: {link}"

    summary = summarize_news(title, content)

    return {"title": title, "summary": summary, "link": link}

summary = summarize_news(news[0]["title"], news[0]["link"])
print("üìå Summary:\n", summary)

def generate_social_post(title, summary, link):
    """Formats the summary into an engaging social media post."""
    return f"üì∞ {summary}"

post = generate_social_post(news[0]["title"], summary, news[0]["link"])
print(post)

from mastodon import Mastodon
from IPython.core.display import display, HTML

def setup_mastodon(access_token):
    """Setup Mastodon API connection using access token."""
    try:
        mastodon = Mastodon(
            access_token=access_token,
            api_base_url='https://mastodon.social'
        )
        # Test the connection
        mastodon.account_verify_credentials()
        display(HTML("<p style='color: green'>‚úÖ Successfully connected to Mastodon!</p>"))
        return mastodon
    except Exception as e:
        display(HTML(f"<p style='color: red'>‚ùå Error setting up Mastodon: {str(e)}</p>"))
        return None

def post_to_mastodon(mastodon, content):
    """Post content to Mastodon."""
    try:
        if mastodon:
            mastodon.status_post(content)
            display(HTML("<p style='color: green'>‚úÖ Successfully posted to Mastodon!</p>"))
            return True
        else:
            display(HTML("<p style='color: red'>‚ùå Mastodon is not properly configured.</p>"))
            return False
    except Exception as e:
        display(HTML(f"<p style='color: red'>‚ùå Error posting to Mastodon: {str(e)}</p>"))
        return False

mastodon = setup_mastodon(access_token)

# for article in news:
#     title = article["title"]
#     link = article["link"]

#     print(f"üîπ Fetching news: {title}")

#     summary = summarize_news(title, link)
#     print(f"üìå Summary:\n{summary}\n")

#     # Generate and post social media content
#     social_post = generate_social_post(title, summary, link)
#     poster.post_to_mastodon(social_post)

title = article['title']
link = article['link']
print(f"üîπ Fetching news: {title}")
summary = summarize_news(title, link)
print(f"üìå Summary:\n{summary}\n")

# Generate and post social media content
social_post = generate_social_post(title, summary, link)
post_to_mastodon(mastodon, social_post)

# !pip install phidata

# !pip install pillow